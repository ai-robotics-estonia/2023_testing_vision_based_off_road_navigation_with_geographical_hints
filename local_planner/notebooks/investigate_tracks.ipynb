{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01024b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/romet/projects/ut/milrem/waypoint_planner\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6103b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import yaml\n",
    "from model.vae import WaypointVAEGNM\n",
    "from model.vae import WaypointVAEExperiment\n",
    "from model.util import load_vae_model\n",
    "from torchvision import transforms\n",
    "from data.dataset import MilremDataset, MilremVizDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed10cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(track, frame_range=None):\n",
    "    data_root = '/home/romet/data2/datasets/extracted_datasets'\n",
    "    data = pd.read_csv(f\"{data_root}/{track}/csv/extracted_data.csv\")\n",
    "    data.sort_values(by=[\"timestamp\"], inplace=True)\n",
    "    data.reset_index(inplace=True)\n",
    "    if frame_range:\n",
    "        print(\"Selecting range: \", frame_range)\n",
    "        data = data.loc[frame_range].copy()\n",
    "    \n",
    "    data['velocity'] = np.sqrt(data['gnss_velocity_x']**2 + data['gnss_velocity_y']**2 + data['gnss_velocity_z']**2)\n",
    "    print(\"Avg velocity: \", data['velocity'].mean())\n",
    "    \n",
    "    old_len = len(data)\n",
    "    filtered_data = data.dropna(subset=['camera_position_x', 'camera_position_y', 'camera_position_z']).copy()\n",
    "    print(\"No camera position filter: \", old_len - len(filtered_data))\n",
    "    \n",
    "    filtered_data['diff_x'] = filtered_data['camera_position_x'].diff().abs()\n",
    "    filtered_data['diff_y'] = filtered_data['camera_position_y'].diff().abs()\n",
    "    filtered_data['diff_z'] = filtered_data['camera_position_z'].diff().abs()\n",
    "        \n",
    "    MAX_TOLERANCE = 1.0\n",
    "    old_len = len(filtered_data)\n",
    "    filtered_data = filtered_data[(filtered_data['diff_x'] < MAX_TOLERANCE) & (filtered_data['diff_y'] < MAX_TOLERANCE) & (filtered_data['diff_z'] < MAX_TOLERANCE)]\n",
    "    print(\"Position max filter: \", old_len - len(filtered_data))\n",
    "    \n",
    "    #MIN_TOLERANCE = 0.0000000000000000001\n",
    "    #old_len = len(filtered_data)\n",
    "    #filtered_data = filtered_data[(filtered_data['diff_x'] > MIN_TOLERANCE) | (filtered_data['diff_y'] > MIN_TOLERANCE) | (filtered_data['diff_z'] > MIN_TOLERANCE)]\n",
    "    #print(\"Position min filter: \", old_len - len(filtered_data))\n",
    "    \n",
    "    VELOCITY_MIN_TOLERANCE = 0.05\n",
    "    VELOCITY_MAX_TOLERANCE = 2.5\n",
    "    old_len = len(filtered_data)\n",
    "    filtered_data = filtered_data[filtered_data['velocity'] > VELOCITY_MIN_TOLERANCE]\n",
    "    filtered_data = filtered_data[filtered_data['velocity'] < VELOCITY_MAX_TOLERANCE]\n",
    "    print(\"Velocity filter: \", old_len - len(filtered_data))\n",
    "    \n",
    "    \n",
    "    removed_ids = list(set(data.index.values) - set(filtered_data.index.values))\n",
    "    removed_ids.sort()\n",
    "    removed_rows = data.loc[removed_ids]\n",
    "    print(\"Total rows filtered: \", len(removed_rows))\n",
    "    \n",
    "    print(\"Total rows: \", len(data))\n",
    "    val_start_index = int(0.9*len(data))\n",
    "    if frame_range and frame_range.start:\n",
    "        val_start_index = val_start_index + frame_range.start\n",
    "    #print(\"Val start index: \", val_start_index)\n",
    "\n",
    "\n",
    "    model_path = \"/home/romet/projects/ut/milrem/drive-any-robot/train/logs/gnm/vae_combined_2023_08_31_19_29_08/latest.pth\"\n",
    "    dataset_path = Path(data_root) / track\n",
    "    \n",
    "    action_losses, distance_losses = calculate_losses(model_path, dataset_path, frame_range)\n",
    "\n",
    "\n",
    "    print(\"Action loss: \", action_losses.mean())\n",
    "    print(\"Distance loss: \", distance_losses.mean())\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(4, 2, figsize=(12, 12))\n",
    "    \n",
    "    marker_size = 3\n",
    "    removed_marker_size = 10\n",
    "    axs[0, 0].scatter(filtered_data['camera_position_x'], filtered_data['camera_position_y'], c=filtered_data['camera_position_z']);\n",
    "    axs[0, 0].set_title(\"Track\")\n",
    "    \n",
    "    axs[0, 1].scatter(filtered_data.index.values, filtered_data['camera_position_x'], c='green', s=marker_size)\n",
    "    axs[0, 1].scatter(removed_rows.index.values, removed_rows['camera_position_x'], c='red', s=removed_marker_size)\n",
    "    axs[0, 1].set_title(\"Camera x position\")\n",
    "    \n",
    "    axs[1, 0].scatter(filtered_data.index.values, filtered_data['camera_position_y'], c='green', s=marker_size)\n",
    "    axs[1, 0].scatter(removed_rows.index.values, removed_rows['camera_position_y'], c='red', s=removed_marker_size)\n",
    "    axs[1, 0].set_title(\"Camera y position\")\n",
    "    \n",
    "    axs[1, 1].scatter(filtered_data.index.values, filtered_data['camera_position_y'], c='green', s=marker_size)\n",
    "    axs[1, 1].scatter(removed_rows.index.values, removed_rows['camera_position_y'], c='red', s=removed_marker_size)\n",
    "    axs[1, 1].set_title(\"Camera z position\")\n",
    "    \n",
    "    axs[2, 0].scatter(filtered_data.index.values, filtered_data['velocity'], c='green', s=marker_size)\n",
    "    axs[2, 0].scatter(removed_rows.index.values, removed_rows['velocity'], c='red', s=removed_marker_size)\n",
    "    axs[2, 0].set_title(\"Velocity\")\n",
    "    \n",
    "    axs[2, 1].plot(filtered_data['velocity'], c='blue')\n",
    "    axs[2, 1].set_title(\"Filtered Velocity\")\n",
    "\n",
    "    axs[3, 0].plot(action_losses)\n",
    "    axs[3, 0].set_title(\"Action losses\")\n",
    "\n",
    "    axs[3, 1].plot(distance_losses)\n",
    "    axs[3, 1].set_title(\"Distance losses\")\n",
    "    \n",
    "    fig.suptitle(track)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_dataset(dataset_path, data_range, config):\n",
    "    transform = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    "    image_transform = transforms.Compose(transform)\n",
    "    aspect_ratio = config[\"image_size\"][0] / config[\"image_size\"][1]\n",
    "    return MilremDataset(dataset_path, image_transform, aspect_ratio, data_range, **config)\n",
    "\n",
    "def calculate_losses(model_path, dataset_path, data_range=slice(None, None)):\n",
    "    with open('config/vae.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    model = load_vae_model(model_path, config)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = load_dataset(dataset_path, data_range, config)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, num_workers=1, batch_size=400, shuffle=False, drop_last=True)\n",
    "    \n",
    "    pred_actions = []\n",
    "    pred_distances = []\n",
    "    \n",
    "    label_actions = []\n",
    "    label_distances = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(dataloader)):\n",
    "            observations, waypoint_img, (action_label, distance_label), metadata = batch\n",
    "            (distance_pred, action_pred), mu, log_var, z = model(observations, waypoint_img)\n",
    "            \n",
    "            pred_actions.extend(action_pred)\n",
    "            pred_distances.extend(distance_pred)\n",
    "        \n",
    "            label_actions.extend(action_label)\n",
    "            label_distances.extend(distance_label)\n",
    "\n",
    "    action_losses = np.array([F.mse_loss(x[0], x[1]).item() for x in zip(pred_actions, label_actions)])\n",
    "    distance_losses = np.array([F.mse_loss(x[0], x[1]).item() for x in zip(pred_distances, label_distances)])\n",
    "    \n",
    "    return action_losses, distance_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0d554-b6d2-4e0f-a87c-254e01db6cfc",
   "metadata": {},
   "source": [
    "+2023-07-17-13-37-10 (None, 8500) (8700, 11800) (12000, 13900) (14100, 21600) (22500, 25000) (26000, 36000) (37000, 40000) (48000, 54500)\n",
    "+2023-07-17-14-38-28 (None, 19500)\n",
    "+2023-07-19-13-12-11 (3500, None)\n",
    "-2023-07-21-11-52-18 (15000, None) NOK trajectories very wrong\n",
    "+2023-07-24-13-53-29 (4500, 19000)\n",
    "2023-07-24-14-25-47 (250, 1250)\n",
    "+2023-07-24-14-29-06 (4500, 16500) (18500, None)\n",
    "-2023-07-26-14-22-18 (10000, None) NOK trajectories totally wrong\n",
    "2023-07-27-14-58-24 (10000, None)\n",
    "2023-07-27-15-46-09 OK\n",
    "2023-07-27-16-12-51 OK\n",
    "2023-08-01-15-47-18 OK\n",
    "2023-08-02-16-27-51 NOK\n",
    "-2023-08-04-11-15-22 (25000, None) NOK very high error\n",
    "2023-08-08-15-40-29 OK\n",
    "2023-08-08-16-37-28 OK\n",
    "+2023-08-09-13-44-25 (1500, 20000) (21000, 50500), (51000, None)\n",
    "2023-08-09-14-07-47 OK\n",
    "2023-08-10-16-19-31 OK\n",
    "2023-08-17-16-16-29 OK\n",
    "2023-08-21-15-17-51 NOK\n",
    "2023-08-22-15-25-30 NOK\n",
    "2023-08-23-15-04-12 OK\n",
    "2023-08-23-15-12-38 OK\n",
    "2023-08-23-15-17-22 OK\n",
    "2023-08-23-15-21-21 OK\n",
    "2023-08-23-15-26-38 OK\n",
    "2023-08-23-15-57-55 OK\n",
    "2023-08-24-16-09-18 (12500, 43000)\n",
    "2023-08-25-15-48-47 OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb3707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting range:  slice(48000, 54500, None)\n",
      "Avg velocity:  1.2452309735521894\n",
      "No camera position filter:  0\n",
      "Position max filter:  1\n",
      "Velocity filter:  88\n",
      "Total rows filtered:  89\n",
      "Total rows:  6501\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/romet/projects/ut/milrem/drive-any-robot/train/logs/gnm/vae_combined_2023_08_31_19_29_08/latest.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#plot_data('2023-07-17-13-37-10', frame_range=slice(26000, 40000));\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mplot_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m2023-07-17-13-37-10\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mslice\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m48000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m54500\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m;\n",
      "Cell \u001B[0;32mIn[3], line 57\u001B[0m, in \u001B[0;36mplot_data\u001B[0;34m(track, frame_range)\u001B[0m\n\u001B[1;32m     54\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/romet/projects/ut/milrem/drive-any-robot/train/logs/gnm/vae_combined_2023_08_31_19_29_08/latest.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     55\u001B[0m dataset_path \u001B[38;5;241m=\u001B[39m Path(data_root) \u001B[38;5;241m/\u001B[39m track\n\u001B[0;32m---> 57\u001B[0m action_losses, distance_losses \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_losses\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_range\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAction loss: \u001B[39m\u001B[38;5;124m\"\u001B[39m, action_losses\u001B[38;5;241m.\u001B[39mmean())\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDistance loss: \u001B[39m\u001B[38;5;124m\"\u001B[39m, distance_losses\u001B[38;5;241m.\u001B[39mmean())\n",
      "Cell \u001B[0;32mIn[3], line 113\u001B[0m, in \u001B[0;36mcalculate_losses\u001B[0;34m(model_path, dataset_path, data_range)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig/vae.yaml\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m    111\u001B[0m     config \u001B[38;5;241m=\u001B[39m yaml\u001B[38;5;241m.\u001B[39msafe_load(file)\n\u001B[0;32m--> 113\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_vae_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    116\u001B[0m dataset \u001B[38;5;241m=\u001B[39m load_dataset(dataset_path, data_range, config)\n",
      "File \u001B[0;32m~/projects/ut/milrem/waypoint_planner/model/util.py:83\u001B[0m, in \u001B[0;36mload_vae_model\u001B[0;34m(model_path, config)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_vae_model\u001B[39m(model_path, config):\n\u001B[1;32m     76\u001B[0m     model \u001B[38;5;241m=\u001B[39m WaypointVAEGNM(config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext_size\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     77\u001B[0m                            config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobs_encoding_size\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     78\u001B[0m                            config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgoal_encoding_size\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     79\u001B[0m                            config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlatent_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     80\u001B[0m                            config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlen_traj_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     81\u001B[0m                            config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearn_angle\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m---> 83\u001B[0m     ckpt \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m     load_checkpoint(model, ckpt)\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/miniconda3/envs/milrem-aire22/lib/python3.9/site-packages/torch/serialization.py:986\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    984\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 986\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    987\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    988\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    989\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    990\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m    991\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/miniconda3/envs/milrem-aire22/lib/python3.9/site-packages/torch/serialization.py:435\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    434\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 435\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    437\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/miniconda3/envs/milrem-aire22/lib/python3.9/site-packages/torch/serialization.py:416\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 416\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/romet/projects/ut/milrem/drive-any-robot/train/logs/gnm/vae_combined_2023_08_31_19_29_08/latest.pth'"
     ]
    }
   ],
   "source": [
    "#plot_data('2023-07-17-13-37-10', frame_range=slice(26000, 40000));\n",
    "plot_data('2023-07-17-13-37-10', frame_range=slice(48000, 54500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fbf58-fca6-4471-ba3b-5c505cc66e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fb347-4679-47f9-9bf8-91ba5022138f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393c2a3-bf91-46be-a836-e341b1c38e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c31229-5dea-47c1-b66f-e4a5b619f701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}